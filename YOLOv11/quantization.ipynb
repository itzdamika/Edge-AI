{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "592e3fa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnxNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Using cached onnx-1.17.0-cp310-cp310-win_amd64.whl.metadata (16 kB)\n",
      "Collecting onnxruntime\n",
      "  Using cached onnxruntime-1.21.0-cp310-cp310-win_amd64.whl.metadata (4.9 kB)\n",
      "Collecting onnxruntime-tools\n",
      "  Using cached onnxruntime_tools-1.7.0-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting numpy>=1.20 (from onnx)\n",
      "  Using cached numpy-2.2.4-cp310-cp310-win_amd64.whl.metadata (60 kB)\n",
      "Collecting protobuf>=3.20.2 (from onnx)\n",
      "  Using cached protobuf-6.30.2-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting coloredlogs (from onnxruntime)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Requirement already satisfied: packaging in d:\\my projects\\edge ai\\edge-ai\\edge-ai\\.venv\\lib\\site-packages (from onnxruntime) (24.2)\n",
      "Collecting sympy (from onnxruntime)\n",
      "  Using cached sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: psutil in d:\\my projects\\edge ai\\edge-ai\\edge-ai\\.venv\\lib\\site-packages (from onnxruntime-tools) (7.0.0)\n",
      "Collecting py-cpuinfo (from onnxruntime-tools)\n",
      "  Using cached py_cpuinfo-9.0.0-py3-none-any.whl.metadata (794 bytes)\n",
      "Collecting py3nvml (from onnxruntime-tools)\n",
      "  Using cached py3nvml-0.2.7-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting xmltodict (from py3nvml->onnxruntime-tools)\n",
      "  Using cached xmltodict-0.14.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime)\n",
      "  Using cached pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Using cached onnx-1.17.0-cp310-cp310-win_amd64.whl (14.5 MB)\n",
      "Using cached onnxruntime-1.21.0-cp310-cp310-win_amd64.whl (11.8 MB)\n",
      "Using cached onnxruntime_tools-1.7.0-py3-none-any.whl (212 kB)\n",
      "Using cached numpy-2.2.4-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "Using cached protobuf-6.30.2-cp310-abi3-win_amd64.whl (431 kB)\n",
      "Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Using cached py_cpuinfo-9.0.0-py3-none-any.whl (22 kB)\n",
      "Using cached py3nvml-0.2.7-py3-none-any.whl (55 kB)\n",
      "Using cached sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached xmltodict-0.14.2-py2.py3-none-any.whl (10.0 kB)\n",
      "Using cached pyreadline3-3.5.4-py3-none-any.whl (83 kB)\n",
      "Installing collected packages: py-cpuinfo, mpmath, flatbuffers, xmltodict, sympy, pyreadline3, protobuf, numpy, py3nvml, onnx, humanfriendly, coloredlogs, onnxruntime-tools, onnxruntime\n",
      "Successfully installed coloredlogs-15.0.1 flatbuffers-25.2.10 humanfriendly-10.0 mpmath-1.3.0 numpy-2.2.4 onnx-1.17.0 onnxruntime-1.21.0 onnxruntime-tools-1.7.0 protobuf-6.30.2 py-cpuinfo-9.0.0 py3nvml-0.2.7 pyreadline3-3.5.4 sympy-1.13.3 xmltodict-0.14.2\n"
     ]
    }
   ],
   "source": [
    "%pip install onnx onnxruntime onnxruntime-tools --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b6327fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
     ]
    }
   ],
   "source": [
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "\n",
    "quantize_dynamic(\n",
    "    model_input=\"../YOLOv11/runs/detect/train/weights/best.onnx\",\n",
    "    model_output=\"../YOLOv11/runs/detect/train/weights/Model.onnx\",\n",
    "    weight_type=QuantType.QInt8,\n",
    "    op_types_to_quantize=[\"MatMul\", \"Conv\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cd7c20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
