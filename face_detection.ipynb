{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 0 existing face embeddings\n",
      "Face embedding for 'Gaindu' saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "from torchvision import transforms\n",
    "\n",
    "# Initialize MTCNN (Face Detection)\n",
    "mtcnn = MTCNN()\n",
    "\n",
    "# Initialize Inception Resnet (Face Recognition)\n",
    "model = InceptionResnetV1(pretrained='vggface2').eval()\n",
    "\n",
    "# Load the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Image preprocessing transform\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((160, 160)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0, 0, 0], std=[255, 255, 255])  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "# Create directory for storing embeddings if it doesn't exist\n",
    "embeddings_dir = 'face_embeddings'\n",
    "if not os.path.exists(embeddings_dir):\n",
    "    os.makedirs(embeddings_dir)\n",
    "\n",
    "# Load existing face embeddings\n",
    "def load_embeddings():\n",
    "    embeddings = {}\n",
    "    if os.path.exists(embeddings_dir):\n",
    "        for filename in os.listdir(embeddings_dir):\n",
    "            if filename.endswith('.pth'):\n",
    "                name = os.path.splitext(filename)[0]\n",
    "                path = os.path.join(embeddings_dir, filename)\n",
    "                embeddings[name] = torch.load(path)\n",
    "    return embeddings\n",
    "\n",
    "# Function to check if face already exists\n",
    "def face_exists(new_embedding, saved_embeddings, threshold=0.7):\n",
    "    if not saved_embeddings:\n",
    "        return False, None\n",
    "    \n",
    "    for name, embedding in saved_embeddings.items():\n",
    "        # Calculate cosine similarity\n",
    "        similarity = torch.nn.functional.cosine_similarity(new_embedding, embedding)\n",
    "        if similarity > threshold:\n",
    "            return True, name\n",
    "    \n",
    "    return False, None\n",
    "\n",
    "# Function to save the face embedding\n",
    "def save_face_embedding(face_tensor, name, saved_embeddings):\n",
    "    # Get the face embedding\n",
    "    with torch.no_grad():\n",
    "        embedding = model(face_tensor).detach()\n",
    "    \n",
    "    # Check if face already exists\n",
    "    exists, existing_name = face_exists(embedding, saved_embeddings)\n",
    "    \n",
    "    if exists:\n",
    "        print(f\"Face already exists as '{existing_name}'\")\n",
    "        return False\n",
    "    \n",
    "    # Save the embedding to a file (in .pth format)\n",
    "    save_path = os.path.join(embeddings_dir, f\"{name}.pth\")\n",
    "    torch.save(embedding, save_path)\n",
    "    print(f\"Face embedding for '{name}' saved successfully!\")\n",
    "    return True\n",
    "\n",
    "# Load existing embeddings\n",
    "saved_embeddings = load_embeddings()\n",
    "print(f\"Loaded {len(saved_embeddings)} existing face embeddings\")\n",
    "\n",
    "# State variables\n",
    "save_mode = False\n",
    "input_name = \"\"\n",
    "current_face_tensor = None\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Create a copy of the frame for display\n",
    "    display_frame = frame.copy()\n",
    "    \n",
    "    # Detect faces\n",
    "    faces, _ = mtcnn.detect(frame)\n",
    "    \n",
    "    if faces is not None:\n",
    "        for face in faces:\n",
    "            if face is not None:\n",
    "                # Draw bounding box around the detected face\n",
    "                x1, y1, x2, y2 = [int(coord) for coord in face]\n",
    "                cv2.rectangle(display_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                \n",
    "                # Crop the face from the frame\n",
    "                face_crop = frame[y1:y2, x1:x2]\n",
    "                \n",
    "                if face_crop.size != 0:\n",
    "                    try:\n",
    "                        # Preprocess the cropped face\n",
    "                        face_tensor = preprocess(face_crop)\n",
    "                        \n",
    "                        # Add batch dimension (for model compatibility)\n",
    "                        face_tensor = face_tensor.unsqueeze(0)\n",
    "                        \n",
    "                        current_face_tensor = face_tensor\n",
    "                        \n",
    "                        # If not in save mode, display instructions\n",
    "                        if not save_mode:\n",
    "                            cv2.putText(display_frame, 'Press \"s\" to save this face', \n",
    "                                        (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing face: {e}\")\n",
    "    \n",
    "    # If in save mode, display the text input interface\n",
    "    if save_mode:\n",
    "        cv2.putText(display_frame, f'Enter name: {input_name}_', \n",
    "                    (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "        cv2.putText(display_frame, 'Press ENTER to confirm or ESC to cancel', \n",
    "                    (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    # Show the frame\n",
    "    cv2.imshow('Face Recognition - Save Face', display_frame)\n",
    "\n",
    "    # Key handling\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    if save_mode:\n",
    "        # Handle text input\n",
    "        if key == 13:  # Enter key\n",
    "            if input_name and current_face_tensor is not None:\n",
    "                success = save_face_embedding(current_face_tensor, input_name, saved_embeddings)\n",
    "                if success:\n",
    "                    saved_embeddings = load_embeddings()  # Reload embeddings\n",
    "                save_mode = False\n",
    "                input_name = \"\"\n",
    "        elif key == 27:  # Esc key\n",
    "            save_mode = False\n",
    "            input_name = \"\"\n",
    "        elif key == 8:  # Backspace\n",
    "            input_name = input_name[:-1] if input_name else \"\"\n",
    "        elif key >= 32 and key <= 126:  # Printable ASCII characters\n",
    "            input_name += chr(key)\n",
    "    else:\n",
    "        # Normal mode key handling\n",
    "        if key == ord('s') and current_face_tensor is not None:\n",
    "            save_mode = True\n",
    "        elif key == 27:  # Esc key to exit\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "from scipy.spatial.distance import cosine\n",
    "from torchvision import transforms\n",
    "\n",
    "# Initialize MTCNN (Face Detection)\n",
    "mtcnn = MTCNN()\n",
    "\n",
    "# Initialize Inception Resnet (Face Recognition)\n",
    "model = InceptionResnetV1(pretrained='vggface2').eval()\n",
    "\n",
    "# Load the saved face embedding (if it exists)\n",
    "saved_embedding = torch.load('my_face_embeddings.pth')\n",
    "\n",
    "# Load the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Threshold for face recognition (cosine distance threshold)\n",
    "threshold = 0.6\n",
    "\n",
    "# Image preprocessing pipeline\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((160, 160)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0, 0, 0], std=[255, 255, 255])  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "# Function to recognize face by comparing embeddings\n",
    "def recognize_face(face_tensor):\n",
    "    # Get the face embedding\n",
    "    embedding = model(face_tensor)\n",
    "    \n",
    "    # Flatten both the saved embedding and the current face embedding to 1D\n",
    "    embedding_flat = embedding.flatten()\n",
    "    saved_embedding_flat = saved_embedding.flatten()\n",
    "    \n",
    "    # Calculate the cosine distance between saved embedding and the current face embedding\n",
    "    distance = cosine(saved_embedding_flat.detach().numpy(), embedding_flat.detach().numpy())\n",
    "    print(f'Cosine distance: {distance}')\n",
    "    \n",
    "    if distance < threshold:\n",
    "        print(\"User recognized: Gaindu\")  # Print the recognized user on the console\n",
    "        return \"Gaindu\"\n",
    "    else:\n",
    "        print(\"User recognized: Unknown\")  # Print \"Unknown\" on the console if not recognized\n",
    "        return \"Unknown\"\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Detect faces\n",
    "    faces, _ = mtcnn.detect(frame)\n",
    "    \n",
    "    if faces is not None:\n",
    "        for face in faces:\n",
    "            # Draw bounding box around the detected face\n",
    "            cv2.rectangle(frame, \n",
    "                          (int(face[0]), int(face[1])), \n",
    "                          (int(face[2]), int(face[3])), \n",
    "                          (0, 255, 0), 2)\n",
    "            \n",
    "            # Crop the face from the frame\n",
    "            face_crop = frame[int(face[1]):int(face[3]), int(face[0]):int(face[2])]\n",
    "            \n",
    "            if face_crop.size != 0:\n",
    "                # Preprocess the cropped face\n",
    "                face_tensor = preprocess(face_crop)\n",
    "\n",
    "                # Add batch dimension (for model compatibility)\n",
    "                face_tensor = face_tensor.unsqueeze(0)\n",
    "\n",
    "                # Recognize the face\n",
    "                label = recognize_face(face_tensor)\n",
    "\n",
    "                # Display the label on the image\n",
    "                cv2.putText(frame, label, (int(face[0]), int(face[1]) - 10), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Show the frame with bounding boxes and labels\n",
    "        cv2.imshow('Face Recognition', frame)\n",
    "\n",
    "    # Exit when the 'Esc' key is pressed (key code 27)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "from scipy.spatial.distance import cosine\n",
    "from torchvision import transforms\n",
    "\n",
    "# Initialize MTCNN (Face Detection)\n",
    "mtcnn = MTCNN()\n",
    "\n",
    "# Initialize Inception Resnet (Face Recognition)\n",
    "model = InceptionResnetV1(pretrained='vggface2').eval()\n",
    "\n",
    "# Directory where face embeddings are stored\n",
    "embeddings_dir = 'face_embeddings'\n",
    "\n",
    "# Load the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Threshold for face recognition (cosine distance threshold)\n",
    "threshold = 0.6\n",
    "\n",
    "# Image preprocessing pipeline\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((160, 160)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0, 0, 0], std=[255, 255, 255])  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "# Function to load all saved face embeddings\n",
    "def load_embeddings():\n",
    "    embeddings = {}\n",
    "    if os.path.exists(embeddings_dir):\n",
    "        for filename in os.listdir(embeddings_dir):\n",
    "            if filename.endswith('.pth'):\n",
    "                name = os.path.splitext(filename)[0]\n",
    "                path = os.path.join(embeddings_dir, filename)\n",
    "                embeddings[name] = torch.load(path)\n",
    "    return embeddings\n",
    "\n",
    "# Load saved embeddings\n",
    "saved_embeddings = load_embeddings()\n",
    "print(f\"Loaded {len(saved_embeddings)} face embeddings\")\n",
    "\n",
    "# Function to recognize face\n",
    "def recognize_face(face_tensor):\n",
    "    # Get the face embedding\n",
    "    with torch.no_grad():\n",
    "        embedding = model(face_tensor).detach()\n",
    "    \n",
    "    # Find the closest match\n",
    "    min_distance = float('inf')\n",
    "    recognized_name = \"Unknown\"\n",
    "    \n",
    "    for name, saved_embedding in saved_embeddings.items():\n",
    "        # Calculate cosine distance\n",
    "        distance = cosine(embedding.flatten().detach().numpy(), \n",
    "                         saved_embedding.flatten().detach().numpy())\n",
    "        \n",
    "        print(f\"Distance from {name}: {distance:.4f}\")\n",
    "        \n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            recognized_name = name\n",
    "    \n",
    "    # Check if the minimum distance is below our threshold\n",
    "    if min_distance < threshold:\n",
    "        print(f\"User recognized: {recognized_name} (distance: {min_distance:.4f})\")\n",
    "        return recognized_name\n",
    "    else:\n",
    "        print(f\"User unknown (min distance: {min_distance:.4f})\")\n",
    "        return \"Unknown\"\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Detect faces\n",
    "    faces, _ = mtcnn.detect(frame)\n",
    "    \n",
    "    if faces is not None and faces.shape[0] > 0:\n",
    "        for face in faces:\n",
    "            if face is not None:\n",
    "                # Draw bounding box around the detected face\n",
    "                x1, y1, x2, y2 = [int(coord) for coord in face]\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                \n",
    "                # Crop the face from the frame\n",
    "                face_crop = frame[y1:y2, x1:x2]\n",
    "                \n",
    "                if face_crop.size != 0:\n",
    "                    try:\n",
    "                        # Preprocess the cropped face\n",
    "                        face_tensor = preprocess(face_crop)\n",
    "                        \n",
    "                        # Add batch dimension (for model compatibility)\n",
    "                        face_tensor = face_tensor.unsqueeze(0)\n",
    "                        \n",
    "                        # Recognize the face\n",
    "                        label = recognize_face(face_tensor)\n",
    "                        \n",
    "                        # Display the label on the image\n",
    "                        cv2.putText(frame, label, (x1, y1 - 10), \n",
    "                                   cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing face: {e}\")\n",
    "\n",
    "    # Show the frame with bounding boxes and labels\n",
    "    cv2.imshow('Face Recognition', frame)\n",
    "\n",
    "    # Exit when the 'Esc' key is pressed (key code 27)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
