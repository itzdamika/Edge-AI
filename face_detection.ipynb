{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "from torchvision import transforms\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize MTCNN (Face Detection)\n",
    "mtcnn = MTCNN(thresholds=[0.7, 0.8, 0.8], device=device)  # Higher thresholds reduce false positives\n",
    "\n",
    "# Initialize Inception Resnet (Face Recognition)\n",
    "model = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
    "\n",
    "# Load the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Image preprocessing transform\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((160, 160)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "# Directory for storing embeddings\n",
    "embeddings_dir = 'face_embeddings'\n",
    "os.makedirs(embeddings_dir, exist_ok=True)\n",
    "\n",
    "# Load existing face embeddings\n",
    "def load_embeddings():\n",
    "    embeddings = {}\n",
    "    for filename in os.listdir(embeddings_dir):\n",
    "        if filename.endswith('.pth'):\n",
    "            name = os.path.splitext(filename)[0]\n",
    "            path = os.path.join(embeddings_dir, filename)\n",
    "            embeddings[name] = torch.load(path, map_location=device)\n",
    "    return embeddings\n",
    "\n",
    "# Function to check if face already exists\n",
    "def face_exists(new_embedding, saved_embeddings, threshold=0.7):\n",
    "    if not saved_embeddings:\n",
    "        return False, None\n",
    "    \n",
    "    similarities = {}\n",
    "    for name, embedding in saved_embeddings.items():\n",
    "        similarity = torch.nn.functional.cosine_similarity(new_embedding, embedding).mean()\n",
    "        similarities[name] = similarity.item()\n",
    "    \n",
    "    best_match = max(similarities, key=similarities.get, default=None)\n",
    "    if best_match and similarities[best_match] > threshold:\n",
    "        return True, best_match\n",
    "    return False, None\n",
    "\n",
    "# Function to save face embedding\n",
    "def save_face_embedding(face_tensor, name, saved_embeddings):\n",
    "    with torch.no_grad():\n",
    "        embedding = model(face_tensor.to(device)).detach()\n",
    "    \n",
    "    exists, existing_name = face_exists(embedding, saved_embeddings)\n",
    "    if exists:\n",
    "        print(f\"Face already exists as '{existing_name}'\")\n",
    "        return False, existing_name\n",
    "    \n",
    "    name = ''.join(c for c in name if c.isalnum())  # Sanitize name\n",
    "    save_path = os.path.join(embeddings_dir, f\"{name}.pth\")\n",
    "    torch.save(embedding, save_path)\n",
    "    print(f\"Face embedding for '{name}' saved successfully!\")\n",
    "    return True, None\n",
    "\n",
    "# Load existing embeddings\n",
    "saved_embeddings = load_embeddings()\n",
    "print(f\"Loaded {len(saved_embeddings)} existing face embeddings\")\n",
    "\n",
    "# State variables\n",
    "save_mode = False\n",
    "input_name = \"\"\n",
    "current_face_tensor = None\n",
    "show_duplicate_alert = False\n",
    "duplicate_name = \"\"\n",
    "alert_start_time = 0\n",
    "alert_duration = 3  # seconds\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    display_frame = frame.copy()\n",
    "    current_time = cv2.getTickCount() / cv2.getTickFrequency()\n",
    "    \n",
    "    # Detect faces\n",
    "    boxes, probs = mtcnn.detect(frame)\n",
    "    if boxes is not None:\n",
    "        for box, prob in zip(boxes, probs):\n",
    "            if prob < 0.9:\n",
    "                continue\n",
    "            \n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            x1, y1, x2, y2 = max(0, x1), max(0, y1), min(frame.shape[1], x2), min(frame.shape[0], y2)\n",
    "            \n",
    "            if x1 < x2 and y1 < y2:\n",
    "                face_crop = frame[y1:y2, x1:x2]\n",
    "                \n",
    "                if face_crop.size > 0:\n",
    "                    try:\n",
    "                        face_tensor = preprocess(face_crop).unsqueeze(0).to(device)\n",
    "                        current_face_tensor = face_tensor\n",
    "                        cv2.rectangle(display_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                        \n",
    "                        if not save_mode and not show_duplicate_alert:\n",
    "                            cv2.putText(display_frame, 'Press \"s\" to save this face', \n",
    "                                        (30, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing face: {e}\")\n",
    "    \n",
    "    if save_mode:\n",
    "        overlay = display_frame.copy()\n",
    "        cv2.rectangle(overlay, (40, 35), (600, 120), (0, 0, 0), -1)\n",
    "        cv2.addWeighted(overlay, 0.5, display_frame, 0.5, 0, display_frame)\n",
    "        cv2.putText(display_frame, f'Enter name: {input_name}_', \n",
    "                    (50, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "        cv2.putText(display_frame, 'Press ENTER to confirm or ESC to cancel', \n",
    "                    (50, 110), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    if show_duplicate_alert and current_time - alert_start_time < alert_duration:\n",
    "        overlay = display_frame.copy()\n",
    "        cv2.rectangle(overlay, (40, 35), (600, 120), (0, 0, 0), -1)\n",
    "        cv2.addWeighted(overlay, 0.7, display_frame, 0.3, 0, display_frame)\n",
    "        cv2.putText(display_frame, f\"User already registered as '{duplicate_name}'\", \n",
    "                    (50, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    cv2.imshow('Face Recognition - Save Face', display_frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    if save_mode:\n",
    "        if key == 13 and input_name and current_face_tensor is not None:\n",
    "            success, existing_name = save_face_embedding(current_face_tensor, input_name, saved_embeddings)\n",
    "            if success:\n",
    "                saved_embeddings = load_embeddings()\n",
    "            else:\n",
    "                show_duplicate_alert, duplicate_name, alert_start_time = True, existing_name, current_time\n",
    "            save_mode, input_name = False, \"\"\n",
    "        elif key == 27:\n",
    "            save_mode, input_name = False, \"\"\n",
    "        elif key == 8:\n",
    "            input_name = input_name[:-1]\n",
    "        elif 32 <= key <= 126:\n",
    "            input_name += chr(key)\n",
    "    elif key == ord('s') and current_face_tensor is not None:\n",
    "        save_mode = True\n",
    "    elif key == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "# from scipy.spatial.distance import cosine\n",
    "# from torchvision import transforms\n",
    "\n",
    "# # Initialize MTCNN (Face Detection)\n",
    "# mtcnn = MTCNN()\n",
    "\n",
    "# # Initialize Inception Resnet (Face Recognition)\n",
    "# model = InceptionResnetV1(pretrained='vggface2').eval()\n",
    "\n",
    "# # Load the saved face embedding (if it exists)\n",
    "# saved_embedding = torch.load('my_face_embeddings.pth')\n",
    "\n",
    "# # Load the webcam\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# # Threshold for face recognition (cosine distance threshold)\n",
    "# threshold = 0.6\n",
    "\n",
    "# # Image preprocessing pipeline\n",
    "# preprocess = transforms.Compose([\n",
    "#     transforms.ToPILImage(),\n",
    "#     transforms.Resize((160, 160)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0, 0, 0], std=[255, 255, 255])  # Normalize to [-1, 1]\n",
    "# ])\n",
    "\n",
    "# # Function to recognize face by comparing embeddings\n",
    "# def recognize_face(face_tensor):\n",
    "#     # Get the face embedding\n",
    "#     embedding = model(face_tensor)\n",
    "    \n",
    "#     # Flatten both the saved embedding and the current face embedding to 1D\n",
    "#     embedding_flat = embedding.flatten()\n",
    "#     saved_embedding_flat = saved_embedding.flatten()\n",
    "    \n",
    "#     # Calculate the cosine distance between saved embedding and the current face embedding\n",
    "#     distance = cosine(saved_embedding_flat.detach().numpy(), embedding_flat.detach().numpy())\n",
    "#     print(f'Cosine distance: {distance}')\n",
    "    \n",
    "#     if distance < threshold:\n",
    "#         print(\"User recognized: Gaindu\")  # Print the recognized user on the console\n",
    "#         return \"Gaindu\"\n",
    "#     else:\n",
    "#         print(\"User recognized: Unknown\")  # Print \"Unknown\" on the console if not recognized\n",
    "#         return \"Unknown\"\n",
    "\n",
    "# while True:\n",
    "#     ret, frame = cap.read()\n",
    "#     if not ret:\n",
    "#         break\n",
    "\n",
    "#     # Detect faces\n",
    "#     faces, _ = mtcnn.detect(frame)\n",
    "    \n",
    "#     if faces is not None:\n",
    "#         for face in faces:\n",
    "#             # Draw bounding box around the detected face\n",
    "#             cv2.rectangle(frame, \n",
    "#                           (int(face[0]), int(face[1])), \n",
    "#                           (int(face[2]), int(face[3])), \n",
    "#                           (0, 255, 0), 2)\n",
    "            \n",
    "#             # Crop the face from the frame\n",
    "#             face_crop = frame[int(face[1]):int(face[3]), int(face[0]):int(face[2])]\n",
    "            \n",
    "#             if face_crop.size != 0:\n",
    "#                 # Preprocess the cropped face\n",
    "#                 face_tensor = preprocess(face_crop)\n",
    "\n",
    "#                 # Add batch dimension (for model compatibility)\n",
    "#                 face_tensor = face_tensor.unsqueeze(0)\n",
    "\n",
    "#                 # Recognize the face\n",
    "#                 label = recognize_face(face_tensor)\n",
    "\n",
    "#                 # Display the label on the image\n",
    "#                 cv2.putText(frame, label, (int(face[0]), int(face[1]) - 10), \n",
    "#                             cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "#         # Show the frame with bounding boxes and labels\n",
    "#         cv2.imshow('Face Recognition', frame)\n",
    "\n",
    "#     # Exit when the 'Esc' key is pressed (key code 27)\n",
    "#     if cv2.waitKey(1) & 0xFF == 27:\n",
    "#         break\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPIO not available — running in mock mode.\n",
      "Running without physical GPIO.\n",
      "Loaded 1 face embeddings\n",
      "Recognition cycle took 0.0810 seconds\n",
      "→ Closest match: Gaindu, Cosine distance: 0.3284\n",
      "[+] Recognized: Gaindu\n",
      "[MOCK] Green LED ON for Gaindu\n",
      "Recognition cycle took 0.1078 seconds\n",
      "→ Closest match: Gaindu, Cosine distance: 0.3964\n",
      "[+] Recognized: Gaindu\n",
      "[MOCK] Green LED ON for Gaindu\n",
      "Recognition cycle took 0.1067 seconds\n",
      "→ Closest match: Gaindu, Cosine distance: 0.4408\n",
      "[+] Recognized: Gaindu\n",
      "[MOCK] Green LED ON for Gaindu\n",
      "Recognition cycle took 0.1135 seconds\n",
      "→ Closest match: Gaindu, Cosine distance: 0.5016\n",
      "[!] ALERT: Unrecognized face!\n",
      "[MOCK] Red LED ON\n",
      "Recognition cycle took 0.1164 seconds\n",
      "Recognition cycle took 0.0618 seconds\n",
      "Recognition cycle took 0.0595 seconds\n",
      "Recognition cycle took 0.0504 seconds\n",
      "Recognition cycle took 0.0446 seconds\n",
      "→ Closest match: Gaindu, Cosine distance: 0.4631\n",
      "[+] Recognized: Gaindu\n",
      "[MOCK] Green LED ON for Gaindu\n",
      "Recognition cycle took 0.1011 seconds\n",
      "Recognition cycle took 0.0462 seconds\n",
      "Recognition cycle took 0.0362 seconds\n",
      "→ Closest match: Gaindu, Cosine distance: 0.3678\n",
      "[+] Recognized: Gaindu\n",
      "[MOCK] Green LED ON for Gaindu\n",
      "Recognition cycle took 0.0835 seconds\n",
      "→ Closest match: Gaindu, Cosine distance: 0.3337\n",
      "[+] Recognized: Gaindu\n",
      "[MOCK] Green LED ON for Gaindu\n",
      "Recognition cycle took 0.0874 seconds\n",
      "Recognition cycle took 0.0318 seconds\n",
      "Recognition cycle took 0.0389 seconds\n",
      "Recognition cycle took 0.0429 seconds\n",
      "Recognition cycle took 0.0378 seconds\n",
      "Recognition cycle took 0.0395 seconds\n",
      "Recognition cycle took 0.0368 seconds\n",
      "Recognition cycle took 0.0385 seconds\n",
      "Recognition cycle took 0.0342 seconds\n",
      "Recognition cycle took 0.0341 seconds\n",
      "Recognition cycle took 0.0371 seconds\n",
      "Recognition cycle took 0.0382 seconds\n",
      "Recognition cycle took 0.0371 seconds\n",
      "Recognition cycle took 0.0383 seconds\n",
      "Recognition cycle took 0.0385 seconds\n",
      "→ Closest match: Gaindu, Cosine distance: 0.3723\n",
      "[+] Recognized: Gaindu\n",
      "[MOCK] Green LED ON for Gaindu\n",
      "Recognition cycle took 0.0866 seconds\n",
      "Recognition cycle took 0.0325 seconds\n",
      "Recognition cycle took 0.0337 seconds\n",
      "Recognition cycle took 0.0387 seconds\n",
      "Recognition cycle took 0.0325 seconds\n",
      "Recognition cycle took 0.0374 seconds\n",
      "Recognition cycle took 0.0426 seconds\n",
      "Recognition cycle took 0.0368 seconds\n",
      "Recognition cycle took 0.0350 seconds\n",
      "Recognition cycle took 0.0427 seconds\n",
      "Recognition cycle took 0.0419 seconds\n",
      "Recognition cycle took 0.0392 seconds\n",
      "Recognition cycle took 0.0395 seconds\n",
      "Recognition cycle took 0.0379 seconds\n",
      "Recognition cycle took 0.0381 seconds\n",
      "Recognition cycle took 0.0353 seconds\n",
      "Recognition cycle took 0.0368 seconds\n",
      "Recognition cycle took 0.0391 seconds\n",
      "Recognition cycle took 0.0321 seconds\n",
      "Recognition cycle took 0.0336 seconds\n",
      "Recognition cycle took 0.0349 seconds\n",
      "Recognition cycle took 0.0384 seconds\n",
      "Recognition cycle took 0.0379 seconds\n",
      "Recognition cycle took 0.0228 seconds\n",
      "Recognition cycle took 0.0346 seconds\n",
      "Recognition cycle took 0.0364 seconds\n",
      "Recognition cycle took 0.0379 seconds\n",
      "Recognition cycle took 0.0401 seconds\n",
      "Recognition cycle took 0.0324 seconds\n",
      "Recognition cycle took 0.0331 seconds\n",
      "Recognition cycle took 0.0343 seconds\n",
      "Recognition cycle took 0.0412 seconds\n",
      "Recognition cycle took 0.0391 seconds\n",
      "Recognition cycle took 0.0388 seconds\n",
      "Recognition cycle took 0.0374 seconds\n",
      "Recognition cycle took 0.0349 seconds\n",
      "Recognition cycle took 0.0311 seconds\n",
      "Recognition cycle took 0.0339 seconds\n",
      "Recognition cycle took 0.0321 seconds\n",
      "Recognition cycle took 0.0333 seconds\n",
      "Recognition cycle took 0.0330 seconds\n",
      "→ Closest match: Gaindu, Cosine distance: 0.2750\n",
      "[+] Recognized: Gaindu\n",
      "[MOCK] Green LED ON for Gaindu\n",
      "Recognition cycle took 0.0812 seconds\n",
      "Recognition cycle took 0.0340 seconds\n",
      "Recognition cycle took 0.0358 seconds\n",
      "Recognition cycle took 0.0325 seconds\n",
      "Recognition cycle took 0.0358 seconds\n",
      "Recognition cycle took 0.0341 seconds\n",
      "→ Closest match: Gaindu, Cosine distance: 1.0222\n",
      "[!] ALERT: Unrecognized face!\n",
      "[MOCK] Red LED ON\n",
      "Recognition cycle took 0.0874 seconds\n",
      "Recognition cycle took 0.0404 seconds\n",
      "Recognition cycle took 0.0365 seconds\n",
      "Recognition cycle took 0.0362 seconds\n",
      "→ Closest match: Gaindu, Cosine distance: 1.0297\n",
      "[!] ALERT: Unrecognized face!\n",
      "[MOCK] Red LED ON\n",
      "Recognition cycle took 0.0819 seconds\n",
      "Recognition cycle took 0.0366 seconds\n",
      "Recognition cycle took 0.0374 seconds\n",
      "Recognition cycle took 0.0338 seconds\n",
      "Recognition cycle took 0.0370 seconds\n",
      "Recognition cycle took 0.0383 seconds\n",
      "Recognition cycle took 0.0398 seconds\n",
      "Recognition cycle took 0.0408 seconds\n",
      "Recognition cycle took 0.0384 seconds\n",
      "Recognition cycle took 0.0363 seconds\n",
      "Recognition cycle took 0.0329 seconds\n",
      "Recognition cycle took 0.0392 seconds\n",
      "Recognition cycle took 0.0336 seconds\n",
      "Recognition cycle took 0.0307 seconds\n",
      "Recognition cycle took 0.0361 seconds\n",
      "Recognition cycle took 0.0372 seconds\n",
      "Recognition cycle took 0.0413 seconds\n",
      "Recognition cycle took 0.0312 seconds\n",
      "Recognition cycle took 0.0360 seconds\n",
      "Recognition cycle took 0.0341 seconds\n",
      "Recognition cycle took 0.0335 seconds\n",
      "Recognition cycle took 0.0353 seconds\n",
      "→ Closest match: Gaindu, Cosine distance: 0.4943\n",
      "[+] Recognized: Gaindu\n",
      "[MOCK] Green LED ON for Gaindu\n",
      "Recognition cycle took 0.0848 seconds\n",
      "Recognition cycle took 0.0312 seconds\n",
      "Recognition cycle took 0.0317 seconds\n",
      "Recognition cycle took 0.0327 seconds\n",
      "Recognition cycle took 0.0302 seconds\n",
      "Recognition cycle took 0.0336 seconds\n",
      "Recognition cycle took 0.0326 seconds\n",
      "Recognition cycle took 0.0320 seconds\n",
      "Recognition cycle took 0.0354 seconds\n",
      "Recognition cycle took 0.0362 seconds\n",
      "Recognition cycle took 0.0404 seconds\n",
      "Recognition cycle took 0.0386 seconds\n",
      "Recognition cycle took 0.0334 seconds\n",
      "Recognition cycle took 0.0351 seconds\n",
      "Recognition cycle took 0.0373 seconds\n",
      "Recognition cycle took 0.0338 seconds\n",
      "Recognition cycle took 0.0350 seconds\n",
      "Recognition cycle took 0.0387 seconds\n",
      "Recognition cycle took 0.0356 seconds\n",
      "Recognition cycle took 0.0298 seconds\n",
      "Recognition cycle took 0.0300 seconds\n",
      "Recognition cycle took 0.0374 seconds\n",
      "Recognition cycle took 0.0419 seconds\n",
      "Recognition cycle took 0.0462 seconds\n",
      "Recognition cycle took 0.0447 seconds\n",
      "Recognition cycle took 0.0337 seconds\n",
      "Recognition cycle took 0.0425 seconds\n",
      "Recognition cycle took 0.0485 seconds\n",
      "Recognition cycle took 0.0375 seconds\n",
      "Recognition cycle took 0.0432 seconds\n",
      "Recognition cycle took 0.0408 seconds\n",
      "Recognition cycle took 0.0447 seconds\n",
      "Recognition cycle took 0.0418 seconds\n",
      "Recognition cycle took 0.0412 seconds\n",
      "Recognition cycle took 0.0329 seconds\n",
      "Recognition cycle took 0.0418 seconds\n",
      "Recognition cycle took 0.0430 seconds\n",
      "Recognition cycle took 0.0370 seconds\n",
      "Recognition cycle took 0.0395 seconds\n",
      "Recognition cycle took 0.0397 seconds\n",
      "Recognition cycle took 0.0400 seconds\n",
      "Recognition cycle took 0.0404 seconds\n",
      "Recognition cycle took 0.0427 seconds\n",
      "Recognition cycle took 0.0443 seconds\n",
      "Recognition cycle took 0.0358 seconds\n",
      "Recognition cycle took 0.0396 seconds\n",
      "→ Closest match: Gaindu, Cosine distance: 0.7009\n",
      "[!] ALERT: Unrecognized face!\n",
      "[MOCK] Red LED ON\n",
      "Recognition cycle took 0.0946 seconds\n",
      "Recognition cycle took 0.0420 seconds\n",
      "→ Closest match: Gaindu, Cosine distance: 0.8800\n",
      "[!] ALERT: Unrecognized face!\n",
      "[MOCK] Red LED ON\n",
      "Recognition cycle took 0.0943 seconds\n",
      "→ Closest match: Gaindu, Cosine distance: 0.6146\n",
      "[!] ALERT: Unrecognized face!\n",
      "[MOCK] Red LED ON\n",
      "→ Closest match: Gaindu, Cosine distance: 0.7802\n",
      "[!] ALERT: Unrecognized face!\n",
      "[MOCK] Red LED ON\n",
      "Recognition cycle took 0.1411 seconds\n",
      "Recognition cycle took 0.0376 seconds\n",
      "→ Closest match: Gaindu, Cosine distance: 0.6957\n",
      "[!] ALERT: Unrecognized face!\n",
      "[MOCK] Red LED ON\n",
      "Recognition cycle took 0.0907 seconds\n",
      "→ Closest match: Gaindu, Cosine distance: 0.9238\n",
      "[!] ALERT: Unrecognized face!\n",
      "[MOCK] Red LED ON\n",
      "Recognition cycle took 0.0914 seconds\n",
      "→ Closest match: Gaindu, Cosine distance: 0.9179\n",
      "[!] ALERT: Unrecognized face!\n",
      "[MOCK] Red LED ON\n",
      "→ Closest match: Gaindu, Cosine distance: 0.9268\n",
      "[!] ALERT: Unrecognized face!\n",
      "[MOCK] Red LED ON\n",
      "Recognition cycle took 0.1323 seconds\n",
      "→ Closest match: Gaindu, Cosine distance: 0.5716\n",
      "[!] ALERT: Unrecognized face!\n",
      "[MOCK] Red LED ON\n",
      "Recognition cycle took 0.0912 seconds\n",
      "→ Closest match: Gaindu, Cosine distance: 0.6903\n",
      "[!] ALERT: Unrecognized face!\n",
      "[MOCK] Red LED ON\n",
      "Recognition cycle took 0.0881 seconds\n",
      "→ Closest match: Gaindu, Cosine distance: 0.6548\n",
      "[!] ALERT: Unrecognized face!\n",
      "[MOCK] Red LED ON\n",
      "Recognition cycle took 0.0922 seconds\n",
      "→ Closest match: Gaindu, Cosine distance: 0.7042\n",
      "[!] ALERT: Unrecognized face!\n",
      "[MOCK] Red LED ON\n",
      "Recognition cycle took 0.0923 seconds\n",
      "→ Closest match: Gaindu, Cosine distance: 0.6878\n",
      "[!] ALERT: Unrecognized face!\n",
      "[MOCK] Red LED ON\n",
      "Recognition cycle took 0.0938 seconds\n",
      "→ Closest match: Gaindu, Cosine distance: 0.7097\n",
      "[!] ALERT: Unrecognized face!\n",
      "[MOCK] Red LED ON\n",
      "Recognition cycle took 0.0939 seconds\n",
      "→ Closest match: Gaindu, Cosine distance: 0.7249\n",
      "[!] ALERT: Unrecognized face!\n",
      "[MOCK] Red LED ON\n",
      "Recognition cycle took 0.0953 seconds\n",
      "→ Closest match: Gaindu, Cosine distance: 0.7675\n",
      "[!] ALERT: Unrecognized face!\n",
      "[MOCK] Red LED ON\n",
      "Recognition cycle took 0.0924 seconds\n",
      "→ Closest match: Gaindu, Cosine distance: 0.6990\n",
      "[!] ALERT: Unrecognized face!\n",
      "[MOCK] Red LED ON\n",
      "Recognition cycle took 0.0939 seconds\n",
      "→ Closest match: Gaindu, Cosine distance: 0.7493\n",
      "[!] ALERT: Unrecognized face!\n",
      "[MOCK] Red LED ON\n",
      "Recognition cycle took 0.0988 seconds\n",
      "→ Closest match: Gaindu, Cosine distance: 0.7861\n",
      "[!] ALERT: Unrecognized face!\n",
      "[MOCK] Red LED ON\n",
      "Recognition cycle took 0.0899 seconds\n",
      "→ Closest match: Gaindu, Cosine distance: 0.6510\n",
      "[!] ALERT: Unrecognized face!\n",
      "[MOCK] Red LED ON\n",
      "Recognition cycle took 0.0999 seconds\n",
      "Recognition cycle took 0.0374 seconds\n",
      "Recognition cycle took 0.0251 seconds\n",
      "Recognition cycle took 0.0364 seconds\n",
      "Recognition cycle took 0.0353 seconds\n",
      "Recognition cycle took 0.0272 seconds\n",
      "Recognition cycle took 0.0351 seconds\n",
      "Recognition cycle took 0.0381 seconds\n",
      "Recognition cycle took 0.0329 seconds\n",
      "Recognition cycle took 0.0338 seconds\n",
      "Recognition cycle took 0.0339 seconds\n",
      "Recognition cycle took 0.0394 seconds\n",
      "Recognition cycle took 0.0359 seconds\n",
      "Recognition cycle took 0.0333 seconds\n",
      "Recognition cycle took 0.0365 seconds\n",
      "Recognition cycle took 0.0426 seconds\n",
      "Recognition cycle took 0.0319 seconds\n",
      "Recognition cycle took 0.0392 seconds\n",
      "Recognition cycle took 0.0318 seconds\n",
      "Recognition cycle took 0.0419 seconds\n",
      "Recognition cycle took 0.0359 seconds\n",
      "Recognition cycle took 0.0378 seconds\n",
      "Recognition cycle took 0.0362 seconds\n",
      "Recognition cycle took 0.0380 seconds\n",
      "Recognition cycle took 0.0367 seconds\n",
      "Recognition cycle took 0.0334 seconds\n",
      "Recognition cycle took 0.0354 seconds\n",
      "Recognition cycle took 0.0319 seconds\n",
      "Recognition cycle took 0.0336 seconds\n",
      "Recognition cycle took 0.0319 seconds\n",
      "Recognition cycle took 0.0363 seconds\n",
      "Recognition cycle took 0.0327 seconds\n",
      "Recognition cycle took 0.0336 seconds\n",
      "Recognition cycle took 0.0351 seconds\n",
      "Recognition cycle took 0.0349 seconds\n",
      "Recognition cycle took 0.0363 seconds\n",
      "Recognition cycle took 0.0348 seconds\n",
      "Recognition cycle took 0.0412 seconds\n",
      "Recognition cycle took 0.0355 seconds\n",
      "Recognition cycle took 0.0338 seconds\n",
      "Recognition cycle took 0.0343 seconds\n",
      "Recognition cycle took 0.0367 seconds\n",
      "Recognition cycle took 0.0348 seconds\n",
      "Recognition cycle took 0.0374 seconds\n",
      "Recognition cycle took 0.0429 seconds\n",
      "Recognition cycle took 0.0370 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "from scipy.spatial.distance import cosine\n",
    "from torchvision import transforms\n",
    "import time\n",
    "\n",
    "# ===== GPIO SETUP (Handles PC or Pi) =====\n",
    "try:\n",
    "    import RPi.GPIO as GPIO\n",
    "    ON_PI = True\n",
    "except (ImportError, RuntimeError):\n",
    "    print(\"GPIO not available — running in mock mode.\")\n",
    "    ON_PI = False\n",
    "\n",
    "if ON_PI:\n",
    "    GPIO.setmode(GPIO.BCM)\n",
    "    GREEN_LED_PIN = 17\n",
    "    RED_LED_PIN = 27\n",
    "    GPIO.setup(GREEN_LED_PIN, GPIO.OUT)\n",
    "    GPIO.setup(RED_LED_PIN, GPIO.OUT)\n",
    "    GPIO.output(GREEN_LED_PIN, GPIO.LOW)\n",
    "    GPIO.output(RED_LED_PIN, GPIO.LOW)\n",
    "else:\n",
    "    GREEN_LED_PIN = RED_LED_PIN = None\n",
    "    def gpio_mock(*args, **kwargs): pass\n",
    "    GPIO = type('GPIO', (), {'output': gpio_mock, 'cleanup': gpio_mock})\n",
    "    print(\"Running without physical GPIO.\")\n",
    "\n",
    "# ===== Initialize Face Detection and Recognition =====\n",
    "mtcnn = MTCNN(thresholds=[0.7, 0.8, 0.8])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
    "\n",
    "embeddings_dir = 'face_embeddings'\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Set lower resolution for Raspberry Pi optimization\n",
    "cap.set(3, 640)  # Width\n",
    "cap.set(4, 480)  # Height\n",
    "\n",
    "threshold = 0.5  # Stricter threshold for better unknown detection\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((160, 160)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "def load_embeddings():\n",
    "    embeddings = {}\n",
    "    if os.path.exists(embeddings_dir):\n",
    "        for filename in os.listdir(embeddings_dir):\n",
    "            if filename.endswith('.pth'):\n",
    "                name = os.path.splitext(filename)[0]\n",
    "                path = os.path.join(embeddings_dir, filename)\n",
    "                embeddings[name] = torch.load(path, map_location=device)\n",
    "    return embeddings\n",
    "\n",
    "saved_embeddings = load_embeddings()\n",
    "print(f\"Loaded {len(saved_embeddings)} face embeddings\")\n",
    "\n",
    "def preprocess_face(face_crop):\n",
    "    # Resize face crop to 160x160 and preprocess to tensor\n",
    "    face_resized = cv2.resize(face_crop, (160, 160))\n",
    "    face_tensor = preprocess(face_resized).unsqueeze(0)  # Normalize and convert to tensor\n",
    "    return face_tensor\n",
    "\n",
    "def recognize_face(face_tensor):\n",
    "    with torch.no_grad():\n",
    "        embedding = model(face_tensor.to(device)).detach().cpu().numpy()\n",
    "    \n",
    "    min_distance = float('inf')\n",
    "    recognized_name = \"Unknown\"\n",
    "    \n",
    "    for name, saved_embedding in saved_embeddings.items():\n",
    "        saved_embedding = saved_embedding.cpu().numpy()  # Ensure numpy is used for comparisons\n",
    "        distance = cosine(embedding.flatten(), saved_embedding.flatten())\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            recognized_name = name\n",
    "    \n",
    "    print(f\"→ Closest match: {recognized_name}, Cosine distance: {min_distance:.4f}\")\n",
    "    \n",
    "    if min_distance < threshold:\n",
    "        return recognized_name, min_distance\n",
    "    else:\n",
    "        return \"Unknown\", min_distance\n",
    "\n",
    "frame_count = 0\n",
    "recognition_frequency = 5  # Perform recognition every 5 frames\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame_count += 1\n",
    "        if frame_count % recognition_frequency == 0:\n",
    "            # Perform face recognition every 5th frame\n",
    "            start_time = time.time()\n",
    "\n",
    "            display_frame = frame.copy()\n",
    "            boxes, probs = mtcnn.detect(frame, landmarks=False)\n",
    "\n",
    "            if ON_PI:\n",
    "                GPIO.output(GREEN_LED_PIN, GPIO.LOW)\n",
    "                GPIO.output(RED_LED_PIN, GPIO.LOW)\n",
    "\n",
    "            if boxes is not None and len(boxes) > 0:\n",
    "                valid_indices = [i for i, prob in enumerate(probs) if prob is not None and prob > 0.7]\n",
    "                valid_boxes = [boxes[i] for i in valid_indices]\n",
    "\n",
    "                for box in valid_boxes:\n",
    "                    x1, y1, x2, y2 = [int(coord) for coord in box]\n",
    "                    x1, y1 = max(0, x1), max(0, y1)\n",
    "                    x2, y2 = min(frame.shape[1], x2), min(frame.shape[0], y2)\n",
    "\n",
    "                    if x1 < x2 and y1 < y2:\n",
    "                        face_crop = frame[y1:y2, x1:x2]\n",
    "\n",
    "                        if face_crop.size > 0:\n",
    "                            try:\n",
    "                                face_tensor = preprocess_face(face_crop)\n",
    "                                label, distance = recognize_face(face_tensor)\n",
    "\n",
    "                                box_color = (0, 255, 0) if label != \"Unknown\" else (0, 0, 255)\n",
    "                                cv2.rectangle(display_frame, (x1, y1), (x2, y2), box_color, 2)\n",
    "\n",
    "                                label_text = f\"{label} ({distance:.2f})\"\n",
    "                                text_size = cv2.getTextSize(label_text, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)[0]\n",
    "                                cv2.rectangle(display_frame, \n",
    "                                              (x1, y1 - text_size[1] - 10), \n",
    "                                              (x1 + text_size[0], y1), \n",
    "                                              box_color, -1)\n",
    "                                cv2.putText(display_frame, label_text, (x1, y1 - 5), \n",
    "                                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "                                if label == \"Unknown\":\n",
    "                                    print(\"[!] ALERT: Unrecognized face!\")\n",
    "                                    if ON_PI:\n",
    "                                        GPIO.output(RED_LED_PIN, GPIO.HIGH)\n",
    "                                    else:\n",
    "                                        print(\"[MOCK] Red LED ON\")\n",
    "                                else:\n",
    "                                    print(f\"[+] Recognized: {label}\")\n",
    "                                    if ON_PI:\n",
    "                                        GPIO.output(GREEN_LED_PIN, GPIO.HIGH)\n",
    "                                    else:\n",
    "                                        print(f\"[MOCK] Green LED ON for {label}\")\n",
    "\n",
    "                            except Exception as e:\n",
    "                                print(f\"Error processing face: {e}\")\n",
    "            \n",
    "            # Optional: Log the time taken for each face detection and recognition cycle\n",
    "            end_time = time.time()\n",
    "            print(f\"Recognition cycle took {end_time - start_time:.4f} seconds\")\n",
    "\n",
    "        cv2.imshow('Face Recognition', display_frame)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:  # ESC key to exit\n",
    "            break\n",
    "\n",
    "finally:\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    if ON_PI:\n",
    "        GPIO.cleanup()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
