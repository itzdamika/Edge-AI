{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "from torchvision import transforms\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize MTCNN (Face Detection)\n",
    "mtcnn = MTCNN(thresholds=[0.7, 0.8, 0.8], device=device)  # Higher thresholds reduce false positives\n",
    "\n",
    "# Initialize Inception Resnet (Face Recognition)\n",
    "model = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
    "\n",
    "# Load the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Image preprocessing transform\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((160, 160)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "# Directory for storing embeddings\n",
    "embeddings_dir = 'face_embeddings'\n",
    "os.makedirs(embeddings_dir, exist_ok=True)\n",
    "\n",
    "# Load existing face embeddings\n",
    "def load_embeddings():\n",
    "    embeddings = {}\n",
    "    for filename in os.listdir(embeddings_dir):\n",
    "        if filename.endswith('.pth'):\n",
    "            name = os.path.splitext(filename)[0]\n",
    "            path = os.path.join(embeddings_dir, filename)\n",
    "            embeddings[name] = torch.load(path, map_location=device)\n",
    "    return embeddings\n",
    "\n",
    "# Function to check if face already exists\n",
    "def face_exists(new_embedding, saved_embeddings, threshold=0.7):\n",
    "    if not saved_embeddings:\n",
    "        return False, None\n",
    "    \n",
    "    similarities = {}\n",
    "    for name, embedding in saved_embeddings.items():\n",
    "        similarity = torch.nn.functional.cosine_similarity(new_embedding, embedding).mean()\n",
    "        similarities[name] = similarity.item()\n",
    "    \n",
    "    best_match = max(similarities, key=similarities.get, default=None)\n",
    "    if best_match and similarities[best_match] > threshold:\n",
    "        return True, best_match\n",
    "    return False, None\n",
    "\n",
    "# Function to save face embedding\n",
    "def save_face_embedding(face_tensor, name, saved_embeddings):\n",
    "    with torch.no_grad():\n",
    "        embedding = model(face_tensor.to(device)).detach()\n",
    "    \n",
    "    exists, existing_name = face_exists(embedding, saved_embeddings)\n",
    "    if exists:\n",
    "        print(f\"Face already exists as '{existing_name}'\")\n",
    "        return False, existing_name\n",
    "    \n",
    "    name = ''.join(c for c in name if c.isalnum())  # Sanitize name\n",
    "    save_path = os.path.join(embeddings_dir, f\"{name}.pth\")\n",
    "    torch.save(embedding, save_path)\n",
    "    print(f\"Face embedding for '{name}' saved successfully!\")\n",
    "    return True, None\n",
    "\n",
    "# Load existing embeddings\n",
    "saved_embeddings = load_embeddings()\n",
    "print(f\"Loaded {len(saved_embeddings)} existing face embeddings\")\n",
    "\n",
    "# State variables\n",
    "save_mode = False\n",
    "input_name = \"\"\n",
    "current_face_tensor = None\n",
    "show_duplicate_alert = False\n",
    "duplicate_name = \"\"\n",
    "alert_start_time = 0\n",
    "alert_duration = 3  # seconds\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    display_frame = frame.copy()\n",
    "    current_time = cv2.getTickCount() / cv2.getTickFrequency()\n",
    "    \n",
    "    # Detect faces\n",
    "    boxes, probs = mtcnn.detect(frame)\n",
    "    if boxes is not None:\n",
    "        for box, prob in zip(boxes, probs):\n",
    "            if prob < 0.9:\n",
    "                continue\n",
    "            \n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "            x1, y1, x2, y2 = max(0, x1), max(0, y1), min(frame.shape[1], x2), min(frame.shape[0], y2)\n",
    "            \n",
    "            if x1 < x2 and y1 < y2:\n",
    "                face_crop = frame[y1:y2, x1:x2]\n",
    "                \n",
    "                if face_crop.size > 0:\n",
    "                    try:\n",
    "                        face_tensor = preprocess(face_crop).unsqueeze(0).to(device)\n",
    "                        current_face_tensor = face_tensor\n",
    "                        cv2.rectangle(display_frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                        \n",
    "                        if not save_mode and not show_duplicate_alert:\n",
    "                            cv2.putText(display_frame, 'Press \"s\" to save this face', \n",
    "                                        (30, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing face: {e}\")\n",
    "    \n",
    "    if save_mode:\n",
    "        overlay = display_frame.copy()\n",
    "        cv2.rectangle(overlay, (40, 35), (600, 120), (0, 0, 0), -1)\n",
    "        cv2.addWeighted(overlay, 0.5, display_frame, 0.5, 0, display_frame)\n",
    "        cv2.putText(display_frame, f'Enter name: {input_name}_', \n",
    "                    (50, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "        cv2.putText(display_frame, 'Press ENTER to confirm or ESC to cancel', \n",
    "                    (50, 110), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    if show_duplicate_alert and current_time - alert_start_time < alert_duration:\n",
    "        overlay = display_frame.copy()\n",
    "        cv2.rectangle(overlay, (40, 35), (600, 120), (0, 0, 0), -1)\n",
    "        cv2.addWeighted(overlay, 0.7, display_frame, 0.3, 0, display_frame)\n",
    "        cv2.putText(display_frame, f\"User already registered as '{duplicate_name}'\", \n",
    "                    (50, 70), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "    \n",
    "    cv2.imshow('Face Recognition - Save Face', display_frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    \n",
    "    if save_mode:\n",
    "        if key == 13 and input_name and current_face_tensor is not None:\n",
    "            success, existing_name = save_face_embedding(current_face_tensor, input_name, saved_embeddings)\n",
    "            if success:\n",
    "                saved_embeddings = load_embeddings()\n",
    "            else:\n",
    "                show_duplicate_alert, duplicate_name, alert_start_time = True, existing_name, current_time\n",
    "            save_mode, input_name = False, \"\"\n",
    "        elif key == 27:\n",
    "            save_mode, input_name = False, \"\"\n",
    "        elif key == 8:\n",
    "            input_name = input_name[:-1]\n",
    "        elif 32 <= key <= 126:\n",
    "            input_name += chr(key)\n",
    "    elif key == ord('s') and current_face_tensor is not None:\n",
    "        save_mode = True\n",
    "    elif key == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "# from scipy.spatial.distance import cosine\n",
    "# from torchvision import transforms\n",
    "\n",
    "# # Initialize MTCNN (Face Detection)\n",
    "# mtcnn = MTCNN()\n",
    "\n",
    "# # Initialize Inception Resnet (Face Recognition)\n",
    "# model = InceptionResnetV1(pretrained='vggface2').eval()\n",
    "\n",
    "# # Load the saved face embedding (if it exists)\n",
    "# saved_embedding = torch.load('my_face_embeddings.pth')\n",
    "\n",
    "# # Load the webcam\n",
    "# cap = cv2.VideoCapture(0)\n",
    "\n",
    "# # Threshold for face recognition (cosine distance threshold)\n",
    "# threshold = 0.6\n",
    "\n",
    "# # Image preprocessing pipeline\n",
    "# preprocess = transforms.Compose([\n",
    "#     transforms.ToPILImage(),\n",
    "#     transforms.Resize((160, 160)),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0, 0, 0], std=[255, 255, 255])  # Normalize to [-1, 1]\n",
    "# ])\n",
    "\n",
    "# # Function to recognize face by comparing embeddings\n",
    "# def recognize_face(face_tensor):\n",
    "#     # Get the face embedding\n",
    "#     embedding = model(face_tensor)\n",
    "    \n",
    "#     # Flatten both the saved embedding and the current face embedding to 1D\n",
    "#     embedding_flat = embedding.flatten()\n",
    "#     saved_embedding_flat = saved_embedding.flatten()\n",
    "    \n",
    "#     # Calculate the cosine distance between saved embedding and the current face embedding\n",
    "#     distance = cosine(saved_embedding_flat.detach().numpy(), embedding_flat.detach().numpy())\n",
    "#     print(f'Cosine distance: {distance}')\n",
    "    \n",
    "#     if distance < threshold:\n",
    "#         print(\"User recognized: Gaindu\")  # Print the recognized user on the console\n",
    "#         return \"Gaindu\"\n",
    "#     else:\n",
    "#         print(\"User recognized: Unknown\")  # Print \"Unknown\" on the console if not recognized\n",
    "#         return \"Unknown\"\n",
    "\n",
    "# while True:\n",
    "#     ret, frame = cap.read()\n",
    "#     if not ret:\n",
    "#         break\n",
    "\n",
    "#     # Detect faces\n",
    "#     faces, _ = mtcnn.detect(frame)\n",
    "    \n",
    "#     if faces is not None:\n",
    "#         for face in faces:\n",
    "#             # Draw bounding box around the detected face\n",
    "#             cv2.rectangle(frame, \n",
    "#                           (int(face[0]), int(face[1])), \n",
    "#                           (int(face[2]), int(face[3])), \n",
    "#                           (0, 255, 0), 2)\n",
    "            \n",
    "#             # Crop the face from the frame\n",
    "#             face_crop = frame[int(face[1]):int(face[3]), int(face[0]):int(face[2])]\n",
    "            \n",
    "#             if face_crop.size != 0:\n",
    "#                 # Preprocess the cropped face\n",
    "#                 face_tensor = preprocess(face_crop)\n",
    "\n",
    "#                 # Add batch dimension (for model compatibility)\n",
    "#                 face_tensor = face_tensor.unsqueeze(0)\n",
    "\n",
    "#                 # Recognize the face\n",
    "#                 label = recognize_face(face_tensor)\n",
    "\n",
    "#                 # Display the label on the image\n",
    "#                 cv2.putText(frame, label, (int(face[0]), int(face[1]) - 10), \n",
    "#                             cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "#         # Show the frame with bounding boxes and labels\n",
    "#         cv2.imshow('Face Recognition', frame)\n",
    "\n",
    "#     # Exit when the 'Esc' key is pressed (key code 27)\n",
    "#     if cv2.waitKey(1) & 0xFF == 27:\n",
    "#         break\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import winsound  # Windows beep sound (use another method for Linux/Mac)\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "from scipy.spatial.distance import cosine\n",
    "from torchvision import transforms\n",
    "\n",
    "# Initialize MTCNN with higher confidence threshold to reduce false positives\n",
    "mtcnn = MTCNN(thresholds=[0.7, 0.8, 0.8])\n",
    "\n",
    "# Initialize Inception Resnet (Face Recognition)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = InceptionResnetV1(pretrained='vggface2').eval().to(device)\n",
    "\n",
    "# Directory where face embeddings are stored\n",
    "embeddings_dir = 'face_embeddings'\n",
    "\n",
    "# Load the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Threshold for face recognition (cosine distance threshold)\n",
    "threshold = 0.6\n",
    "\n",
    "# Image preprocessing pipeline\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((160, 160)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# Function to load all saved face embeddings\n",
    "def load_embeddings():\n",
    "    embeddings = {}\n",
    "    if os.path.exists(embeddings_dir):\n",
    "        for filename in os.listdir(embeddings_dir):\n",
    "            if filename.endswith('.pth'):\n",
    "                name = os.path.splitext(filename)[0]\n",
    "                path = os.path.join(embeddings_dir, filename)\n",
    "                embeddings[name] = torch.load(path, map_location=device)\n",
    "    return embeddings\n",
    "\n",
    "# Load saved embeddings\n",
    "saved_embeddings = load_embeddings()\n",
    "print(f\"Loaded {len(saved_embeddings)} face embeddings\")\n",
    "\n",
    "# Function to recognize face\n",
    "def recognize_face(face_tensor):\n",
    "    with torch.no_grad():\n",
    "        embedding = model(face_tensor.to(device)).detach().cpu()\n",
    "    \n",
    "    min_distance = float('inf')\n",
    "    recognized_name = \"Unknown\"\n",
    "    \n",
    "    for name, saved_embedding in saved_embeddings.items():\n",
    "        saved_embedding = saved_embedding.cpu() if isinstance(saved_embedding, torch.Tensor) else torch.tensor(saved_embedding)\n",
    "        distance = cosine(embedding.flatten().numpy(), saved_embedding.flatten().numpy())\n",
    "        \n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            recognized_name = name\n",
    "    \n",
    "    return (recognized_name, min_distance) if min_distance < threshold else (\"Unknown\", min_distance)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    display_frame = frame.copy()\n",
    "    boxes, probs = mtcnn.detect(frame, landmarks=False)\n",
    "    \n",
    "    if boxes is not None and len(boxes) > 0:\n",
    "        valid_indices = [i for i, prob in enumerate(probs) if prob is not None and prob > 0.9]\n",
    "        valid_boxes = [boxes[i] for i in valid_indices]\n",
    "        \n",
    "        for box in valid_boxes:\n",
    "            x1, y1, x2, y2 = [int(coord) for coord in box]\n",
    "            x1, y1 = max(0, x1), max(0, y1)\n",
    "            x2, y2 = min(frame.shape[1], x2), min(frame.shape[0], y2)\n",
    "            \n",
    "            if x1 < x2 and y1 < y2:\n",
    "                face_crop = frame[y1:y2, x1:x2]\n",
    "                \n",
    "                if face_crop.size > 0:\n",
    "                    try:\n",
    "                        face_tensor = preprocess(face_crop).unsqueeze(0)\n",
    "                        label, distance = recognize_face(face_tensor)\n",
    "                        \n",
    "                        box_color = (0, 255, 0) if label != \"Unknown\" else (0, 0, 255)\n",
    "                        cv2.rectangle(display_frame, (x1, y1), (x2, y2), box_color, 2)\n",
    "                        \n",
    "                        label_text = f\"{label} ({distance:.2f})\" if label != \"Unknown\" else \"Unknown\"\n",
    "                        text_size = cv2.getTextSize(label_text, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)[0]\n",
    "                        cv2.rectangle(display_frame, \n",
    "                                     (x1, y1 - text_size[1] - 10), \n",
    "                                     (x1 + text_size[0], y1), \n",
    "                                     box_color, -1)\n",
    "                        cv2.putText(display_frame, label_text, (x1, y1 - 5), \n",
    "                                  cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "                        \n",
    "                        if label == \"Unknown\":\n",
    "                            print(\"ALERT: Unrecognized user detected!\")\n",
    "                            winsound.Beep(1000, 500)  # Windows beep (1000 Hz, 500 ms)\n",
    "                            \n",
    "                    except Exception as e:\n",
    "                        print(f\"Error processing face: {e}\")\n",
    "\n",
    "    cv2.imshow('Face Recognition', display_frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
