{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "\n",
    "# Initialize MTCNN (Face Detection)\n",
    "mtcnn = MTCNN()\n",
    "\n",
    "# Initialize Inception Resnet (Face Recognition)\n",
    "model = InceptionResnetV1(pretrained='vggface2').eval()\n",
    "\n",
    "# Load the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Function to save the face embedding\n",
    "def save_face_embedding(face_tensor):\n",
    "    # Get the face embedding\n",
    "    embedding = model(face_tensor)\n",
    "    \n",
    "    # Save the embedding to a file (in .pth format)\n",
    "    torch.save(embedding, 'my_face_embeddings.pth')\n",
    "    print(\"Face embedding saved successfully!\")\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Detect faces\n",
    "    faces, _ = mtcnn.detect(frame)\n",
    "    \n",
    "    if faces is not None:\n",
    "        for face in faces:\n",
    "            # Draw bounding box around the detected face\n",
    "            cv2.rectangle(frame, \n",
    "                          (int(face[0]), int(face[1])), \n",
    "                          (int(face[2]), int(face[3])), \n",
    "                          (0, 255, 0), 2)\n",
    "            \n",
    "            # Crop the face from the frame\n",
    "            face_crop = frame[int(face[1]):int(face[3]), int(face[0]):int(face[2])]\n",
    "            \n",
    "            if face_crop.size != 0:\n",
    "                # Resize the face crop to 160x160 pixels (required for FaceNet)\n",
    "                face_crop_resized = cv2.resize(face_crop, (160, 160))\n",
    "\n",
    "                # Convert to RGB\n",
    "                face_crop_rgb = cv2.cvtColor(face_crop_resized, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                # Convert to PyTorch tensor\n",
    "                face_tensor = torch.FloatTensor(face_crop_rgb).permute(2, 0, 1)\n",
    "\n",
    "                # Normalize the image to [-1, 1]\n",
    "                face_tensor = (face_tensor / 255.0) * 2 - 1\n",
    "\n",
    "                # Add batch dimension\n",
    "                face_tensor = face_tensor.unsqueeze(0)\n",
    "\n",
    "                # Ask for confirmation to save the embedding\n",
    "                cv2.putText(frame, 'Press \"s\" to save your face', (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Show the frame\n",
    "        cv2.imshow('Face Recognition - Save Face', frame)\n",
    "\n",
    "    # Check if 's' key is pressed to save the embedding\n",
    "    if cv2.waitKey(1) & 0xFF == ord('s'):\n",
    "        save_face_embedding(face_tensor)\n",
    "\n",
    "    # Exit when the 'Esc' key is pressed (key code 27)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from facenet_pytorch import MTCNN, InceptionResnetV1\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Initialize MTCNN (Face Detection)\n",
    "mtcnn = MTCNN()\n",
    "\n",
    "# Initialize Inception Resnet (Face Recognition)\n",
    "model = InceptionResnetV1(pretrained='vggface2').eval()\n",
    "\n",
    "# Load the saved face embedding (if it exists)\n",
    "saved_embedding = torch.load('my_face_embeddings.pth')\n",
    "\n",
    "# Load the webcam\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Threshold for face recognition (cosine distance threshold)\n",
    "threshold = 0.6\n",
    "\n",
    "\n",
    "# Function to recognize face by comparing embeddings\n",
    "def recognize_face(face_tensor):\n",
    "    # Get the face embedding\n",
    "    embedding = model(face_tensor)\n",
    "    \n",
    "    # Flatten both the saved embedding and the current face embedding to 1D\n",
    "    embedding_flat = embedding.flatten()\n",
    "    saved_embedding_flat = saved_embedding.flatten()\n",
    "    \n",
    "    # Calculate the cosine distance between saved embedding and the current face embedding\n",
    "    distance = cosine(saved_embedding_flat.detach().numpy(), embedding_flat.detach().numpy())\n",
    "    print(f'Cosine distance: {distance}')\n",
    "    \n",
    "    if distance < threshold:\n",
    "        print(\"User recognized: Gaindu\")  # Print the recognized user on the console\n",
    "        return \"Gaindu\"\n",
    "    else:\n",
    "        print(\"User recognized: Unknown\")  # Print \"Unknown\" on the console if not recognized\n",
    "        return \"Unknown\"\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Detect faces\n",
    "    faces, _ = mtcnn.detect(frame)\n",
    "    \n",
    "    if faces is not None:\n",
    "        for face in faces:\n",
    "            # Draw bounding box around the detected face\n",
    "            cv2.rectangle(frame, \n",
    "                          (int(face[0]), int(face[1])), \n",
    "                          (int(face[2]), int(face[3])), \n",
    "                          (0, 255, 0), 2)\n",
    "            \n",
    "            # Crop the face from the frame\n",
    "            face_crop = frame[int(face[1]):int(face[3]), int(face[0]):int(face[2])]\n",
    "            \n",
    "            if face_crop.size != 0:\n",
    "                # Resize the face crop to 160x160 pixels (required for FaceNet)\n",
    "                face_crop_resized = cv2.resize(face_crop, (160, 160))\n",
    "\n",
    "                # Convert to RGB\n",
    "                face_crop_rgb = cv2.cvtColor(face_crop_resized, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                # Convert to PyTorch tensor\n",
    "                face_tensor = torch.FloatTensor(face_crop_rgb).permute(2, 0, 1)\n",
    "\n",
    "                # Normalize the image to [-1, 1]\n",
    "                face_tensor = (face_tensor / 255.0) * 2 - 1\n",
    "\n",
    "                # Add batch dimension\n",
    "                face_tensor = face_tensor.unsqueeze(0)\n",
    "\n",
    "                # Recognize the face\n",
    "                label = recognize_face(face_tensor)\n",
    "\n",
    "                # Display the label on the image\n",
    "                cv2.putText(frame, label, (int(face[0]), int(face[1]) - 10), \n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "        # Show the frame with bounding boxes and labels\n",
    "        cv2.imshow('Face Recognition', frame)\n",
    "\n",
    "    # Exit when the 'Esc' key is pressed (key code 27)\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
